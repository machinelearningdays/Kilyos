{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p90lOyhH6M8J"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATASET_ROOT = \"data\"\n",
        "\n",
        "AUDIO_SUBFOLDER = \"audio\"\n",
        "NOISE_SUBFOLDER = \"noise\"\n",
        "\n",
        "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
        "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
        "\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "SHUFFLE_SEED = 58\n",
        "\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4A8M-Vr6M8i",
        "outputId": "18cfd87f-c049-4056-ecd8-5bf1e3d389bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
        "    return audio\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n",
        "\n",
        "\n",
        "class_names = os.listdir(DATASET_AUDIO_PATH)\n",
        "print(\"Our class names: {}\".format(class_names,))\n",
        "\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"pfff = \", label, name)\n",
        "    print(\"Processing speaker {}\".format(name,))\n",
        "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")\n",
        "\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "num_val_samples = int(VALID_SPLIT * len(audio_paths))\n",
        "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "print(\"Using {} files for validation.\".format(num_val_samples))\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our class names: ['data1', 'data2']\n",
            "pfff =  0 data1\n",
            "Processing speaker data1\n",
            "pfff =  1 data2\n",
            "Processing speaker data2\n",
            "Found 891 files belonging to 2 classes.\n",
            "Using 802 files for training.\n",
            "Using 89 files for validation.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f64c86cd950> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7f64c86cd950> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f64c86cde18> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7f64c86cde18> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMMOhnC6M8n",
        "outputId": "9642617b-c53b-4e0d-88b0-48c4db08b174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
        "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(x, 32, 2)\n",
        "    x = residual_block(x, 64, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "model = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 8000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 8000, 16)     64          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 8000, 16)     0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 8000, 16)     784         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 8000, 16)     32          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 8000, 16)     0           conv1d_2[0][0]                   \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 8000, 16)     0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 4000, 16)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 4000, 32)     1568        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4000, 32)     0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 4000, 32)     3104        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 4000, 32)     544         max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 4000, 32)     0           conv1d_5[0][0]                   \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4000, 32)     0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 2000, 32)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 2000, 64)     6208        max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 2000, 64)     0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 2000, 64)     12352       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 2000, 64)     0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 2000, 64)     12352       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 2000, 64)     2112        max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 2000, 64)     0           conv1d_9[0][0]                   \n",
            "                                                                 conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 2000, 64)     0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 1000, 64)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 1000, 128)    24704       max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1000, 128)    0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 1000, 128)    49280       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 1000, 128)    0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 1000, 128)    49280       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 1000, 128)    8320        max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1000, 128)    0           conv1d_13[0][0]                  \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 1000, 128)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 500, 128)     0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 500, 128)     49280       max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 500, 128)     0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 500, 128)     49280       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 500, 128)     0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 500, 128)     49280       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 500, 128)     16512       max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 500, 128)     0           conv1d_17[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 500, 128)     0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 250, 128)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 83, 128)      0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10624)        0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          2720000     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 2)            258         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,088,210\n",
            "Trainable params: 3,088,210\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLIDmWLU6M8y",
        "outputId": "798c8b06-8804-4a56-a9b6-eea9c9c69e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=5,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7/7 [==============================] - 64s 9s/step - loss: 1.7493 - accuracy: 0.5698 - val_loss: 0.5137 - val_accuracy: 0.6966\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 41s 6s/step - loss: 0.3969 - accuracy: 0.7781 - val_loss: 0.3238 - val_accuracy: 0.8315\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 40s 6s/step - loss: 0.3111 - accuracy: 0.8441 - val_loss: 0.2644 - val_accuracy: 0.8315\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 44s 6s/step - loss: 0.2974 - accuracy: 0.8392 - val_loss: 0.2696 - val_accuracy: 0.8315\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 45s 6s/step - loss: 0.2409 - accuracy: 0.8753 - val_loss: 0.1983 - val_accuracy: 0.9775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8AbIL-d6M82",
        "outputId": "4f40f9a6-f602-4395-ecfe-82734c254be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(model.evaluate(valid_ds))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 293ms/step - loss: 0.1983 - accuracy: 0.9775\n",
            "[0.1982947736978531, 0.9775280952453613]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}